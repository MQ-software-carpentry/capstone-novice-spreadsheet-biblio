---
title: "Transforming and Loading Data into a database"
teaching: 20
exercises: 10
questions:
- What is the idea of a loosely coupled system?
- Why are we not connecting directly to the database from python?
objectives:
- "Design a normalised database for this author data"
- "Create a series of tab delimited files for that database"
- "Load the transformed data into the database"
keypoints:
- "Explain why inferences drawn from unnormalized data are always approximate."
---

# Normalisation


# Transforming Data


We now have (key, author) pairs.
The next step is to put them in a relational database
so that we can start asking and answering questions.
Our starting point is the final script from the previous topic:

~~~ 
# display-authors-2.py
# Print (key, author) pairs.

import sys
import csv

with open(sys.argv[1], 'r') as raw:
    reader = csv.reader(raw);
    for line in reader:
        key, authors = line[0], line[3]
        for auth in authors.split('; '): # semi-colon plus space instead of semi-colon
            print key, auth

~~~
{: .language-python}

whose output looks like this:

~~~ 
8SW85SQM McClelland, James L
85QV9X5F McClelland, J. L.
85QV9X5F McNaughton, B. L.
85QV9X5F O'Reilly, R. C.
Z4X6DT6N Ratcliff, R.
F5DGU3Q4 McCloskey, M.
F5DGU3Q4 Cohen, N. J.
PNGQMCP5 Buciluǎ, Cristian
PNGQMCP5 Caruana, Rich
PNGQMCP5 Niculescu-Mizil, Alexandru
~~~
{: .output}

BBS FIXME change this to use the data loader from the previous part.

What we *want* is a series of SQL `insert` statements:

~~~ 
insert into data values('8SW85SQM', 'McClelland, James L');
insert into data values('85QV9X5F', 'McClelland, J. L.');
insert into data values('85QV9X5F', 'McNaughton, B. L.');
~~~
{: .language-sql}

so let's modify the program to print this instead:

~~~ 
# convert-1.py
# Create SQL statements to put (key, author) pairs in a database.

import sys
import csv

INSERT = "insert into data values('{0}', '{1}');"

with open(sys.argv[1], 'r') as raw:
    reader = csv.reader(raw);
    for line in reader:
        key, authors = line[0], line[3]
        for auth in authors.split('; '):
            print INSERT.format(key, auth)

~~~
{: .language-python}

The first change is the definition of `INSERT`,
which is the format string for our insertion statements.
The second change is that instead of printing the key and author directly,
we interpolate those values into `INSERT` using `str.format`.

> ## Cutting Corners 
>
> Python and other languages have libraries for interacting with databases,
> so why are we piping `insert` statements into SQLite instead?
> The answer is that it's a simple solution
> that uses all of the tools we have introduced so far.
> If we had to do anything more complicated with this data,
> we would almost certainly `import sqlite3` and do things the right way.
{: .callout}


This works,
but only if by "works" we mean
"runs to completion without an obvious error".
Upon closer inspection,
there are two problems:

1.  Nobody is actually creating a database table
    for us to insert things into.

2.  Authors names can contain single quotes.

The first is easy to solve ---
we just add this at the start of our program:

~~~ 
CREATE = 'create table data(key text not null, author text not null);'
~~~
{: .language-python .language-sql}

and print it out before printing any of the `insert` statements.
The second problem is trickier:
if we interpolate a name like "O'Mear, Fiona" into `INSERT`,
the result will be:

~~~ 
"insert into data values('RJS8QDC4', 'O'Mear, Fiona');"
~~~
{: .language-python .language-sql}

which isn't legal Python.
The fix there is simply to use double quotes around our strings instead of single quotes,
since people's names can't contain the former.
Once we make this change,
our whole program is:

~~~ 
# convert-2.py
# Create database of keys and authors.

import sys
import csv

CREATE = 'create table data(key text not null, author text not null);'
INSERT = 'insert into data values("{0}", "{1}");'

print CREATE

with open(sys.argv[1], 'r') as raw:
    reader = csv.reader(raw);
    for line in reader:
        key, authors = line[0], line[3]
        for auth in authors.split('; '):
            print INSERT.format(key, auth)

~~~
{: .language-python}

Let's run it:

~~~ 
$ python code/convert-2.py data/bibliography.csv | head -5
create table data(key text not null, author text not null);
insert into data values("8SW85SQM", "McClelland, James L");
insert into data values("85QV9X5F", "McClelland, J. L.");
insert into data values("85QV9X5F", "McNaughton, B. L.");
insert into data values("85QV9X5F", "O'Reilly, R. C.");
~~~
{: .language-sql .output}

That looks pretty good,
so let's use it to create an actual database:

~~~ 
$ python code/convert-2.py data/bibliography.csv | sqlite3 bibliography.db
~~~
{: .language-bash}
This pipeline takes about four seconds to run on my laptop,
and creates a 205 kbyte file called `bibliography.db`.
Let's have a look at what that database contains:

~~~ 
$ sqlite3 bibliography.db
SQLite version 3.8.5 2014-08-15 22:37:57
Enter ".help" for usage hints.

sqlite> .schema
CREATE TABLE data(key text not null, author text not null);

sqlite> select * from data limit 10;
8SW85SQM|McClelland, James L
85QV9X5F|McClelland, J. L.
85QV9X5F|McNaughton, B. L.
85QV9X5F|O'Reilly, R. C.
Z4X6DT6N|Ratcliff, R.
F5DGU3Q4|McCloskey, M.
F5DGU3Q4|Cohen, N. J.
PNGQMCP5|Buciluǎ, Cristian
PNGQMCP5|Caruana, Rich
PNGQMCP5|Niculescu-Mizil, Alexandru
~~~
{: .source .language-sql}

That looks good,
so let's try asking some questions:

~~~ 
select author, count(*) from data group by author order by count(*) desc limit 10;
~~~
{: :source .language-sql}

~~~ 
Bengio, Yoshua|122
Bengio, Y.|111
Hinton, Geoffrey E.|78
LeCun, Yann|56
Hinton, G. E.|45
Salakhutdinov, Ruslan|34
LeCun, Y.|31
Vincent, Pascal|29
Jordan, M. I.|27
Frasconi, P.|25
~~~
{: .output}

The first thing we see is that our work has paid off:
we can now find out who the most prolific authors are with a single command.
The second thing we see is that we're not done yet:
"Bengio, Yoshua" and "Bengio, Y." are almost certainly the same person,
as are "LeCun, Yann" and "LeCun, Y.".
If we really want to know who has written the most papers,
we're going to have to reconcile different names for the same person.

> ## Denormalization is the Root of Much Evil 
>
> Data is **normalized** if it contains no redundancy.
> (The full definition has more conditions, but this is good enough for our purposes.)
> Our data is denormalized
> because it represents particular authors in several different ways.
> We can try to normalize the data using **heuristics** such as,
> "If the surname matches and the initialized form of the other parts of the name match, it's the same person."
> Errors will always creep in, however:
> in our case,
> we have no way of knowing whether "Albar, M." is Mohammd Albar or Michael Albar.
> Answers based on heuristically normalized data are therefore always approximations of reality.
> It is crucial in these cases that we record the heuristics we used
> and the transformations we made
> so that others (including our future selves)
> can check our work.
{: .callout}

Instead of normalizing names,
let's see what other questions we can answer.
Who has co-authored papers with whom?

~~~ 
select a.author, b.author from data a join data b on a.key=b.key and a.author > b.author limit 10;
~~~
{: .source .language-sql}

~~~ 
McNaughton, B. L.|McClelland, J. L.
O'Reilly, R. C.|McClelland, J. L.
O'Reilly, R. C.|McNaughton, B. L.
McCloskey, M.|Cohen, N. J.
Caruana, Rich|Buciluǎ, Cristian
Niculescu-Mizil, Alexandru|Buciluǎ, Cristian
Niculescu-Mizil, Alexandru|Caruana, Rich
Rigamonti, Roberto|Fua, Pascal
Rigamonti, Roberto|Lepetit, Vincent
Sironi, Amos|Fua, Pascal
~~~
{: .output}

(We use `a.author > b.author` to ensure that
each distinct pair of authors only shows up once.)
What if we want to know how often different pairs of people have written together?

~~~ 
select a.author, b.author, count(*)
from data a join data b
on a.key=b.key and a.author > b.author
group by a.author, b.author
order by count(*) desc
limit 10;
~~~
{: .source .language-sql}

~~~ 
Vincent, Pascal|Bengio, Yoshua|27
Roux, Nicolas Le|Bengio, Yoshua|20
Delalleau, Olivier|Bengio, Yoshua|19
Bengio, Y.|Bengio, S.|18
Larochelle, Hugo|Bengio, Yoshua|15
Roux, Nicolas Le|Delalleau, Olivier|15
Vincent, P.|Bengio, Y.|15
Chapados, N.|Bengio, Y.|14
Gori, M.|Frasconi, P.|14
Salakhutdinov, Ruslan|Hinton, Geoffrey E.|14
~~~
{: .output}

Again,
we have a data normalization problem:
the pair "Vincent, Pascal" and "Bengio, Yoshua"
is almost certainly the same as the pair "Bengio, Y." and "Bengio, S.".
But that problem would be there
even if we were analyzing this data manually,
and putting it in a database has made asking new questions so easy
that we can do research we otherwise wouldn't have been able to tackle.
The final step is to commit our script to Git
and celebrate with a nice cup of tea.

> ## Doing Things the Right Way 
>
> Rewrite the Python program to use the `sqlite3` library to create the database
> instead of `print` statements.
{: .challenge}

> ## Distinct Pairs 
>
> Explain why using `a.author > b.author` ensures that
> distinct pairs of authors only show up once.
{: .challenge}

> ## Normalization 
>
> Write a function that takes two authors' names as input
> and returns `True` if they are probably the same person
> and `False` if they do not.
> Compare your function to your neighbor's:
> can you find a case where the two would disagree?
{: .challenge}

> ## Normalization (continuted) 
>
> Use the function you wrote in the previous challenge
> to normalize authors' names.
> Compare your output to your neighbor's:
> have you produced exactly the same list of author names?
> If not,
> have you produced an equivalent list?
{: .challenge}

{% include links.md %}

